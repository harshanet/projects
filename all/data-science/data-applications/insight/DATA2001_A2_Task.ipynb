{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d723e85",
   "metadata": {
    "id": "1d723e85"
   },
   "source": [
    "# DATA2001 Assignment 2 (Weight: 25%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aaa603",
   "metadata": {
    "id": "d1aaa603"
   },
   "source": [
    "The aim of this assignment is to gain practical experience in analysing unstructured data.\n",
    "You should only submit your completed Jupyter notebook in .ipynb format via Blackboard, including written answers in markdown and results from executed code cells.\n",
    "\n",
    "\n",
    "The assignment comprises 5 main tasks: Data Exploration, Data Preprocessing, Model Training, Model Evaluation, and Model Analysis. You will address and compare two tasks: sentiment analysis and rating prediction.\n",
    "\n",
    "\n",
    "The dataset you will work with in this assignment comprises text reviews about various android applications and their corresponding ratings. Further information about the dataset can be found [here](https://huggingface.co/datasets/sealuzh/app_reviews).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d693423b",
   "metadata": {
    "id": "d693423b"
   },
   "source": [
    "## Task 1: Data Exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562d2289",
   "metadata": {
    "id": "562d2289"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "1. Load the dataset from the file \"app_review.csv\". How many records does the dataset contain? How many distinct classes are there in the dataset? Randomly select and print 5 reviews with a rating of '1' and 5 reviews with a rating of '5'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "797f6daa",
   "metadata": {
    "id": "797f6daa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c359a67",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3c359a67",
    "outputId": "dbca4439-0887-4f0c-8189-22e15a67bfe4"
   },
   "outputs": [],
   "source": [
    "# Provide your answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd562630-30df-44f1-9a32-2ef53d38ed9b",
   "metadata": {},
   "source": [
    "2. Is the class distribution balanced? To support your answer, create a bar plot with the classes on the x-axis and the number of reviews in each class on the y-axis. Additionally, based on your observations of the reviews and the class distribution, determine whether there are more positive or negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "353a41f1-ef77-40d4-9118-d3964d79ee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide your answers here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66c6232",
   "metadata": {
    "id": "c66c6232"
   },
   "source": [
    "## Task 2: Data Preprocessing\n",
    "\n",
    "- Use the provided \"clean_data\" function to remove unnecessary symbols and clean the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18e84d29",
   "metadata": {
    "id": "18e84d29"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_data(text):\n",
    "\n",
    "    # Format words and remove unwanted characters\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text)\n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'br', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5311b4cd",
   "metadata": {
    "id": "5311b4cd"
   },
   "outputs": [],
   "source": [
    "# Provide your answers here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5334f4bc",
   "metadata": {
    "id": "5334f4bc"
   },
   "source": [
    "- Split the clean dataset into separate train and test sets. For this, use the \"Review\" field as the feature vector (X) and the \"Rating\" field as the label vector (Y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2b74af8",
   "metadata": {
    "id": "e2b74af8"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f21e0206",
   "metadata": {
    "id": "f21e0206"
   },
   "outputs": [],
   "source": [
    "# Provide your answers here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f40611",
   "metadata": {
    "id": "41f40611"
   },
   "source": [
    "\n",
    "- Transform the cleaned data into a numerical representation using Bag of Words (BoW) and remove any stop words. Save the BoW representation in the variables train_data_BOW and test_data_BOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0beb3e6e-baa5-4af6-a566-3c8f4c8ef4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a080e62a-1d03-4d23-b024-d736d0707883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide your answers here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3441fac",
   "metadata": {
    "id": "c3441fac"
   },
   "source": [
    "## Task 3: Model Training\n",
    "\n",
    "Define 2 Logistic Regression models: *model1* and *model2* and train the models as follows:\n",
    "- Train the first Logistic Regression model to predict the application rating (Y).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af6007d5",
   "metadata": {
    "id": "af6007d5"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Provide your answers here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cb5069",
   "metadata": {
    "id": "f5cb5069"
   },
   "source": [
    "- Create an additional binary label by assigning ‘1’ – positive for the product ratings 4 and 5; and \"–1\" for product ratings 1, 2 and 3. Store it in y_train_binary and y_test_binary.\n",
    "\n",
    "*Tip: you can use a function copy.deepcopy for creating a copy of label variables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea7fe3f2",
   "metadata": {
    "id": "ea7fe3f2"
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1c3f189",
   "metadata": {
    "id": "a1c3f189"
   },
   "outputs": [],
   "source": [
    "# Provide your answers here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f88e29f-a3b6-4532-9947-6b05aa4db974",
   "metadata": {},
   "source": [
    "- Train the second Logistic Regression model to predict the binary sentiment label (Y_binary).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "107d87c6-977d-4939-91ee-cebb7f4007f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide your answers here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3776991d-06fa-4270-8b92-4247d65476ce",
   "metadata": {},
   "source": [
    "\n",
    "- Make and store predictions for both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11710c39-c1c0-416e-8eee-2c09d0e0a7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide your answers here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f37e686",
   "metadata": {
    "id": "9f37e686"
   },
   "source": [
    "\n",
    "## Task 4: Model Evaluation\n",
    "\n",
    "- Compute and compare the test accuracy of Model 1 and Model 2. Based on your results, analyze which task is easier: binary sentiment prediction or multi-class rating prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09217a19",
   "metadata": {
    "id": "09217a19"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Provide your answers here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974df47c",
   "metadata": {
    "id": "974df47c"
   },
   "source": [
    "\n",
    "\n",
    "- For Model 1,  compute additional evaluaton measures, namely confusion matrix, precision and recall.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c064f3d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "c064f3d6",
    "outputId": "fa668122-752f-45b9-8a8d-d7114e8810f7"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "# Provide your answers here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dd31d7",
   "metadata": {
    "id": "c3dd31d7"
   },
   "source": [
    "- Based on the confusion matrix obtained in the previous question (referring to Model 1, the Logistic Regression for rating prediction), identify and state the number of samples that were classified to have the rating of 1 (the lowest rating), but in reality, they had an actual rating of 5 (the highest rating)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5fd638",
   "metadata": {
    "id": "3e5fd638"
   },
   "source": [
    "**Provide your answer here**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c0632f",
   "metadata": {
    "id": "39c0632f"
   },
   "source": [
    "## Task 5: Model Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c867478",
   "metadata": {
    "id": "1c867478"
   },
   "source": [
    "- Discuss the importance of considering alternative evaluation measures, such as precision and recall, instead of relying solely on accuracy. Based on this discussion, identify the most suitable evaluation metric for Model 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a496792b",
   "metadata": {
    "id": "a496792b"
   },
   "source": [
    "**Provide your answer here**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad234f27",
   "metadata": {
    "id": "ad234f27"
   },
   "source": [
    "\n",
    "- For binary sentiment prediction (Model 2), visualize important words with their model coefficients.  \n",
    "\n",
    "*Tip: you can reuse the function plot_coefficients from prac. session.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "373c09a2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "373c09a2",
    "outputId": "aa1c97d1-71a9-4050-f721-1faaf813e747"
   },
   "outputs": [],
   "source": [
    "# Provide your answers here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c930b90-6b67-4b2e-8884-ccc5dec69663",
   "metadata": {},
   "source": [
    "- Analyze the quality of the features produced by Model 2 by examining the words with the highest coefficients for both the positive and negative classes.  Identify any potential bias in the model, and explain how this bias could affect its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb079ad-a92d-48bf-86c6-4c3fa940628b",
   "metadata": {
    "id": "sTpe-CTd9u0C"
   },
   "source": [
    "**Provide your answer here**\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
